{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import codecs\n",
    "from gensim import corpora,models,similarities\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对句子分词、去停用词\n",
    "def tokenization(str_text):\n",
    "    res = []\n",
    "    words = jieba.cut_for_search(str_text)\n",
    "    #words = jieba.cut(str_text)\n",
    "    #print(' '.join(words))\n",
    "    for word in words:\n",
    "        #去掉不想要的特殊字符\n",
    "        if word == '(' or word == ')':\n",
    "            continue\n",
    "        else:\n",
    "            res.append(word)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_searchStr_forUniversity(search_str,get_search_list):\n",
    "    str_list = get_search_list\n",
    "    corpus = []\n",
    "    for each in str_list:  \n",
    "        corpus.append(tokenization(each['title']))\n",
    "    #建立词袋模型，生成字典和向量语料\n",
    "    print(corpus)\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    doc_vectors = [dictionary.doc2bow(text) for text in corpus]\n",
    "    print('doc_vectors:',doc_vectors)\n",
    "    #建立tf-idf模型\n",
    "    tfidf = models.TfidfModel(doc_vectors)\n",
    "    tfidf_vectors = tfidf[doc_vectors]\n",
    "    #len(tfidf_vectors) = 文本数  len(tfidf_vectors[0] == 第一个文本中的词数量)\n",
    "    #print(len(tfidf_vectors))\n",
    "    \n",
    "    #构建LSI模型，设置主题数（类数）\n",
    "    lsi = models.LsiModel(tfidf_vectors,id2word = dictionary,num_topics=2)\n",
    "    lsi_vector = lsi[tfidf_vectors]\n",
    "    #LSI向量空间中，所有文本的向量都是二维的\n",
    "    query = tokenization(search_str)\n",
    "    query_bow = dictionary.doc2bow(query)\n",
    "    query_lsi = lsi[query_bow]\n",
    "    print(query)\n",
    "    index = similarities.MatrixSimilarity(lsi_vector)\n",
    "    sims = index[query_lsi]\n",
    "    print(list(enumerate(sims)))\n",
    "    \n",
    "    max_index = list(sims).index(max(sims))\n",
    "    res_dict = {}\n",
    "    res_dict.update(search_str = search_str)\n",
    "    if max(sims) == 0:\n",
    "        res_dict.update(url = None)\n",
    "    else:\n",
    "        res_dict.update(url = get_search_list[max_index]['url'])\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_searchStr_forCompany(search_str,get_search_list):\n",
    "    str_list = get_search_list\n",
    "    corpus = []\n",
    "    for each in str_list:    \n",
    "        corpus.append(tokenization(each['title']+each['address']))\n",
    "    #建立词袋模型，生成字典和向量语料\n",
    "    print(corpus)\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    doc_vectors = [dictionary.doc2bow(text) for text in corpus]\n",
    "    print('doc_vectors:',doc_vectors)\n",
    "    #建立tf-idf模型\n",
    "    tfidf = models.TfidfModel(doc_vectors)\n",
    "    tfidf_vectors = tfidf[doc_vectors]\n",
    "    #len(tfidf_vectors) = 文本数  len(tfidf_vectors[0] == 第一个文本中的词数量)\n",
    "    #print(len(tfidf_vectors))\n",
    "    \n",
    "    query = tokenization(search_str)\n",
    "    print(query)\n",
    "    query_bow = dictionary.doc2bow(query)\n",
    "    print(query_bow)\n",
    "    index = similarities.MatrixSimilarity(tfidf_vectors)\n",
    "    sims = index[query_bow]\n",
    "    print(list(enumerate(sims)))\n",
    "       \n",
    "    max_index = list(sims).index(max(sims))\n",
    "   \n",
    "    res_dict = {}\n",
    "    res_dict.update(search_str = search_str)\n",
    "    if max(sims) == 0:\n",
    "        res_dict.update(url = None)\n",
    "    else:\n",
    "        res_dict.update(url = get_search_list[max_index]['url'])\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTheMostSimiStr(search,get_search_list):\n",
    "    search_str = search['title_search']\n",
    "    query = tokenization(search_str)   \n",
    "    if '大学' in query or '学校' in query or '学院' in query:\n",
    "        res_titile = similarity_searchStr_forUniversity(search_str,get_search_list)\n",
    "    else:\n",
    "        res_titile = similarity_searchStr_forCompany(search_str,get_search_list)\n",
    "    return res_titile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_search_list = [{'title': '中国海关管理干部学院', 'url': 'ss','sdress':''}, {'title': '管理干部学院', 'url': 'dddd'},{'title': '中国海关管理干部学院副院长', 'url': 's'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_str = {'title_search':'海关管理干部学院'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['中国', '海关', '中国海', '中国海关', '管理', '干部', '学院'], ['管理', '干部', '学院'], ['中国', '海关', '中国海', '中国海关', '管理', '干部', '学院', '副', '院长']]\n",
      "doc_vectors: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1)], [(3, 1), (4, 1), (6, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]]\n",
      "['海关', '管理', '干部', '学院']\n",
      "[(0, 1.0), (1, 0.0), (2, 0.46270883)]\n"
     ]
    }
   ],
   "source": [
    "res = toTheMostSimiStr(search_str,get_search_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_search_list1 = [{'title': '中国第一汽车集团哈尔滨轻型车场', 'url': 'ss'}, {'title': '中国成人院校', 'url': 'dddd'},{'title': '中国海关管理干部学院副院长', 'url': 'ddds'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_str1 = '哈尔滨轻型车厂职工大学'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['中国', '第一', '汽车', '集团', '汽车集团', '哈尔', '哈尔滨', '轻型', '轻型车', '场'], ['中国', '成人', '院校'], ['中国', '海关', '中国海', '中国海关', '管理', '干部', '学院', '副', '院长']]\n",
      "doc_vectors: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1)], [(0, 1), (10, 1), (11, 1)], [(0, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1)]]\n",
      "['哈尔', '哈尔滨', '轻型', '轻型车', '厂', '职工', '工大', '大学', '职工大学']\n",
      "[(0, 1.0), (1, 0.0), (2, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "res1 = toTheMostSimiStr(search_str1,get_search_list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_str3 = '搜易贷'\n",
    "get_search_list3 = [{'title':'北京信息技术','url':'ssss','address': '天津市滨海新区滨海欣嘉园商业广场五号楼1-18门C53'},{'title': '青岛搜易贷经济信息咨询有限公司', 'url': 'dddd','address': '青岛市滨海新区滨海欣嘉园商业广场五号楼1-18门C53'},{'title': '搜易贷(北京)金融信息服务有限公司', 'url': 'ddds','address': '北京市滨海新区滨海欣嘉园商业广场五号楼1-18门C53'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['北京', '信息', '技术', '信息技术', '天津', '津市', '天津市', '滨海', '新区', '滨海新区', '滨海', '欣嘉园', '商业', '广场', '商业广场', '五号', '楼', '1', '-', '18', '门', 'C53'], ['青岛', '搜易贷', '经济', '信息', '咨询', '有限', '公司', '有限公司', '青岛', '青岛市', '滨海', '新区', '滨海新区', '滨海', '欣嘉园', '商业', '广场', '商业广场', '五号', '楼', '1', '-', '18', '门', 'C53'], ['搜易贷', '北京', '金融', '信息', '金融信息', '服务', '有限', '公司', '有限公司', '北京', '京市', '北京市', '滨海', '新区', '滨海新区', '滨海', '欣嘉园', '商业', '广场', '商业广场', '五号', '楼', '1', '-', '18', '门', 'C53']]\n",
      "doc_vectors: [[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 2), (19, 1), (20, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (8, 1), (9, 1), (12, 1), (14, 1), (15, 1), (16, 1), (18, 2), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 2), (28, 1)], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (7, 2), (8, 1), (9, 1), (12, 1), (14, 1), (15, 1), (16, 1), (18, 2), (19, 1), (20, 1), (21, 1), (23, 1), (24, 1), (25, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1)]]\n",
      "['搜易贷']\n",
      "[(23, 1)]\n",
      "[(0, 0.0), (1, 0.13436423), (2, 0.14955845)]\n"
     ]
    }
   ],
   "source": [
    "res1 = toTheMostSimiStr(search_str3,get_search_list3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_str': '搜易贷', 'url': 'ddds'}"
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_titile3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
