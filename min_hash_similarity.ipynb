{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba.posseg as pseg\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['搜易', '贷'], ['搜易', '贷', '北京', '金融信息', '服务', '有限公司'], ['青岛', '搜易', '贷', '经济', '信息', '咨询', '有限公司']]\n",
      "['搜易', '贷']\n",
      "Estimated Jaccard for data1 and data2 is 0.390625\n",
      "Estimated Jaccard for data1 and data3 is 0.296875\n",
      "Actual Jaccard for data1 and data2 is 0.3333333333333333\n",
      "Actual Jaccard for data1 and data3 is 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "#构建停用词表\n",
    "def stopwords_list(filepath):\n",
    "    stop_words_file = filepath\n",
    "    stopwords = codecs.open(stop_words_file,'r',encoding='utf8').readlines()\n",
    "    stopwords_list = [words.strip() for words in stopwords]\n",
    "    stop_flag = ['x', 'c', 'u','d', 'p', 't', 'uj', 'm', 'f', 'r']\n",
    "    return stopwords_list,stop_flag\n",
    "\n",
    "#对一篇文章，或者句子分词、去停用词\n",
    "def tokenization(filename):\n",
    "    res = []\n",
    "    with open(filename,'r') as f:\n",
    "        text = f.read()\n",
    "        words = pseg.cut(text)\n",
    "    stopwordslist,stop_flag = stopwords_list('/Users/taoxudong/huli/test/stop_words.txt')\n",
    "    #分词特性？中文对应着stop_flag的含义。？？？？？？\n",
    "    for word,flag in words:\n",
    "        if word not in stopwordslist and flag not in stop_flag:\n",
    "            if word != '\\t':\n",
    "                res.append(word)\n",
    "    return res\n",
    "\n",
    "#加载要处理的文本，进行分词\n",
    "filenames = ['/Users/taoxudong/huli/test/测试数据一.txt',\n",
    "            '/Users/taoxudong/huli/test/测试数据二.txt',\n",
    "            '/Users/taoxudong/huli/test/测试数据四.txt']\n",
    "\n",
    "corpus = []\n",
    "for each in filenames:\n",
    "    corpus.append(tokenization(each))\n",
    "print(corpus)\n",
    "\n",
    "data1 = corpus[0]\n",
    "print(data1)\n",
    "data2 = corpus[1]\n",
    "data3 = corpus[2]\n",
    "m1, m2 = MinHash(), MinHash()\n",
    "m3 = MinHash()\n",
    "for d in data1:\n",
    "    m1.update(d.encode('utf8'))\n",
    "for d in data2:\n",
    "    m2.update(d.encode('utf8'))\n",
    "for d in data3:\n",
    "    m3.update(d.encode('utf8'))\n",
    "print(\"Estimated Jaccard for data1 and data2 is\", m1.jaccard(m2))\n",
    "print(\"Estimated Jaccard for data1 and data3 is\", m1.jaccard(m3))\n",
    "s1 = set(data1)\n",
    "s2 = set(data2)\n",
    "s3 = set(data3)\n",
    "actual_jaccard = float(len(s1.intersection(s2)))/float(len(s1.union(s2)))\n",
    "actual_jaccard_2 = float(len(s1.intersection(s2)))/float(len(s1.union(s3)))\n",
    "\n",
    "print(\"Actual Jaccard for data1 and data2 is\", actual_jaccard)\n",
    "print(\"Actual Jaccard for data1 and data3 is\", actual_jaccard_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
